from __future__ import annotations


__copyright__ = "Copyright (C) 2018 Alexandru Fikl"

__license__ = """
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
"""

import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import TYPE_CHECKING, cast

import numpy as np
import numpy.linalg as la
from typing_extensions import override

import loopy as lp
from arraycontext import Array, ArrayContainer, PyOpenCLArrayContext, flatten
from meshmode.discretization import Discretization
from meshmode.dof_array import DOFArray
from pytools import log_process, memoize_in

from pytential import GeometryCollection, bind, sym
from pytential.qbx import QBXLayerPotentialSource
from pytential.source import PointPotentialSource
from pytential.target import PointsTarget


if TYPE_CHECKING:
    from collections.abc import Callable, Sequence

    import optype.numpy as onp

    from sumpy.expansion import ExpansionBase
    from sumpy.kernel import Kernel

    from pytential.linalg.utils import IndexList
    from pytential.symbolic.dof_desc import DOFDescriptorLike


logger = logging.getLogger(__name__)

__doc__ = """
Proxy Point Generation
~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: ProxyPointSource
.. autoclass:: ProxyPointTarget
.. autoclass:: ProxyClusterGeometryData

.. autoclass:: ProxyGeneratorBase
.. autoclass:: ProxyGenerator
    :show-inheritance:
.. autoclass:: QBXProxyGenerator
    :show-inheritance:

.. autofunction:: gather_cluster_neighbor_points
"""

# FIXME: this is just an arbitrary value
_DEFAULT_MAX_PARTICLES_IN_BOX = 32


# {{{ proxy points

class ProxyPointSource(PointPotentialSource):
    """
    .. automethod:: get_expansion_for_qbx_direct_eval
    """

    lpot_source: QBXLayerPotentialSource

    def __init__(self,
            lpot_source: QBXLayerPotentialSource,
            proxies: Array) -> None:
        """
        :arg lpot_source: the layer potential for which the proxy are constructed.
        :arg proxies: an array of shape ``(ambient_dim, nproxies)`` containing
            the proxy points.
        """
        assert proxies.shape[0] == lpot_source.ambient_dim

        super().__init__(proxies)
        self.lpot_source = lpot_source

    def get_expansion_for_qbx_direct_eval(
            self, base_kernel: Kernel, target_kernels: Sequence[Kernel]
        ) -> ExpansionBase:
        """Wrapper around
        ``pytential.qbx.QBXLayerPotentialSource.get_expansion_for_qbx_direct_eval``
        to allow this class to be used by the matrix builders.
        """
        return self.lpot_source.get_expansion_for_qbx_direct_eval(
                base_kernel, target_kernels)


class ProxyPointTarget(PointsTarget):
    lpot_source: QBXLayerPotentialSource

    def __init__(self,
            lpot_source: QBXLayerPotentialSource,
            proxies: Array) -> None:
        """
        :arg lpot_source: the layer potential for which the proxy are constructed.
            This argument is kept for symmetry with :class:`ProxyPointSource`.
        :arg proxies: an array of shape ``(ambient_dim, nproxies)`` containing
            the proxy points.
        """
        assert proxies.shape[0] == lpot_source.ambient_dim

        super().__init__(proxies)
        self.lpot_source = lpot_source


@dataclass(frozen=True)
class ProxyClusterGeometryData:
    """The proxy information generated by  :class:`ProxyGeneratorBase`.

    .. autoattribute:: places
    .. autoattribute:: dofdesc

    .. autoattribute:: nclusters
    .. autoattribute:: srcindex
    .. autoattribute:: pxyindex
    .. autoattribute:: points
    .. autoattribute:: centers
    .. autoattribute:: radii
    .. autoattribute:: cluster_radii

    .. automethod:: __init__
    .. automethod:: to_numpy
    .. automethod:: as_sources
    .. automethod:: as_targets
    """

    places: GeometryCollection
    """Geometry collection containing the used :attr:`dofdesc`."""
    dofdesc: sym.DOFDescriptor
    """A descriptor for the geometry used to compute the proxy points."""

    srcindex: IndexList
    """A :class:`~pytential.linalg.utils.IndexList` describing which cluster
    of points each proxy ball was created from.
    """
    pxyindex: IndexList
    """A :class:`~pytential.linalg.utils.IndexList` describing which proxies
    belong to which cluster.
    """

    points: Array
    """A concatenated array of all the proxy points. Can be sliced into
    using :attr:`pxyindex` (shape ``(dim, nproxies)``).
    """
    centers: Array
    """An array of all the proxy ball centers (shape ``(dim, nclusters)``)."""
    radii: Array
    """An array of all the proxy ball radii (shape ``(nclusters,)``)."""
    cluster_radii: Array
    """An array of all the cluster ball radii (shape ``(nclusters,)``). The
    proxy radii are essentially just the cluster radii multiplied by the
    ``radius_factor``.
    """

    @property
    def nclusters(self) -> int:
        """Number of clusters."""
        return self.srcindex.nclusters

    @property
    def discr(self) -> Discretization:
        """The discretization that corresponds to :attr:`dofdesc` in :attr:`places`."""
        discr = self.places.get_discretization(
            self.dofdesc.geometry, self.dofdesc.discr_stage)
        assert isinstance(discr, Discretization)

        return discr

    def to_numpy(self, actx: PyOpenCLArrayContext) -> ProxyClusterGeometryData:
        from dataclasses import replace
        return replace(self,
                points=np.stack(actx.to_numpy(self.points)),
                centers=np.stack(actx.to_numpy(self.centers)),
                radii=actx.to_numpy(self.radii),
                cluster_radii=self.cluster_radii)

    def as_sources(self) -> ProxyPointSource:
        lpot_source = self.places.get_geometry(self.dofdesc.geometry)
        assert isinstance(lpot_source, QBXLayerPotentialSource)

        return ProxyPointSource(lpot_source, self.points)

    def as_targets(self) -> ProxyPointTarget:
        lpot_source = self.places.get_geometry(self.dofdesc.geometry)
        assert isinstance(lpot_source, QBXLayerPotentialSource)

        return ProxyPointTarget(lpot_source, self.points)

# }}}


# {{{ proxy point generator


def _generate_unit_sphere(
        ambient_dim: int,
        approx_npoints: int) -> onp.Array2D[np.floating]:
    """Generate uniform points on a unit sphere.

    :arg ambient_dim: dimension of the ambient space.
    :arg approx_npoints: approximate number of points to generate. If the
        ambient space is 3D, this will not generate the exact number of points.
    :return: array of shape ``(ambient_dim, npoints)``, where ``npoints``
        will not generally be the same as ``approx_npoints``.
    """

    if ambient_dim == 2:
        t = np.linspace(0.0, 2.0 * np.pi, approx_npoints, endpoint=False)
        points = np.vstack([np.cos(t), np.sin(t)])
    elif ambient_dim == 3:
        from pytools import sphere_sample_equidistant
        points = sphere_sample_equidistant(approx_npoints, r=1)
    else:
        raise ValueError("ambient_dim > 3 not supported.")

    return points


def make_compute_cluster_centers_kernel_ex(
        actx: PyOpenCLArrayContext, ndim: int, norm_type: str) -> lp.ExecutorBase:
    @memoize_in(actx, (make_compute_cluster_centers_kernel_ex, ndim, norm_type))
    def prg() -> lp.ExecutorBase:
        if norm_type == "l2":
            # NOTE: computes first-order approximation of the source centroids
            insns = """
            proxy_center[idim, icluster] = 1.0 / npoints \
                    * simul_reduce(sum, i, sources[idim, srcindices[i + ioffset]])
            """
        elif norm_type == "linf":
            # NOTE: computes the centers of the bounding box
            insns = """
            <> bbox_max = \
                    simul_reduce(max, i, sources[idim, srcindices[i + ioffset]])
            <> bbox_min = \
                    simul_reduce(min, i, sources[idim, srcindices[i + ioffset]])

            proxy_center[idim, icluster] = (bbox_max + bbox_min) / 2.0
            """
        else:
            raise ValueError(f"unknown norm type: '{norm_type}'")

        knl = lp.make_kernel([
            "{[icluster]: 0 <= icluster < nclusters}",
            "{[i]: 0 <= i < npoints}",
            "{[idim]: 0 <= idim < ndim}"
            ],
            f"""
            for icluster
                <> ioffset = srcstarts[icluster]
                <> npoints = srcstarts[icluster + 1] - ioffset

                {insns}
            end
            """, [
                lp.GlobalArg("sources", None,
                    shape=(ndim, "nsources"), dim_tags="sep,C", offset=lp.auto),
                lp.ValueArg("nsources", np.int64),
                ...
                ],
            name="compute_cluster_centers_knl",
            assumptions="ndim>=1 and nclusters>=1",
            fixed_parameters={"ndim": ndim},
            lang_version=lp.MOST_RECENT_LANGUAGE_VERSION,
            )

        knl = lp.tag_inames(knl, "idim*:unr")
        knl = lp.split_iname(knl, "icluster", 64, outer_tag="g.0")

        return knl.executor(actx.context)

    return prg()


class ProxyGeneratorBase(ABC):
    r"""
    .. autoattribute:: places
    .. autoattribute:: radius_factor
    .. autoattribute:: norm_type
    .. autoattribute:: ref_points
    .. autoattribute:: nproxy

    .. automethod:: __init__
    .. automethod:: __call__
    """

    places: GeometryCollection
    radius_factor: float
    """Factor multiplying the cluster radius. This is currently fixed for all
    clusters.
    """
    norm_type: str
    """The type of the norm used to compute the bounding box of the cluster. The
    "radius" is also computed in terms of this norm. Can be one of ``"l2"`` or
    ``"linf"``.
    """
    ref_points: onp.Array2D[np.floating]
    """Reference proxy points on the unit sphere. The reference points are
    translated and scaled for each cluster.
    """

    def __init__(
            self,
            places: GeometryCollection,
            approx_nproxy: int | None = None,
            radius_factor: float | None = None,
            norm_type: str = "linf",

            _generate_ref_proxies:
                Callable[[int], onp.Array2D[np.floating]] | None = None,
            ) -> None:
        """
        :param approx_nproxy: desired number of proxy points. In higher
            dimensions, it is not always possible to construct a proxy ball
            with exactly this number of proxy points. The exact number of
            proxy points can be retrieved with :attr:`nproxy`.
        :param radius_factor: Factor multiplying the cluster radius (i.e radius
            of the bounding box) to get the proxy ball radius.
        :param norm_type: type of the norm used to compute the centers of
            each cluster. Supported values are ``"linf"`` and ``"l2"``.
        """
        generate_ref_proxies = _generate_ref_proxies
        if generate_ref_proxies is None:
            from functools import partial
            generate_ref_proxies = partial(_generate_unit_sphere, places.ambient_dim)

        from pytential import GeometryCollection
        if not isinstance(places, GeometryCollection):
            places = GeometryCollection(places)

        if norm_type not in ("l2", "linf"):
            raise ValueError(
                    f"unsupported norm type: '{norm_type}' "
                    + "(expected one of 'l2' or 'linf')")

        if radius_factor is None:
            # FIXME: this is a fairly arbitrary value
            radius_factor = 1.1

        if approx_nproxy is None:
            # FIXME: this is a fairly arbitrary value
            approx_nproxy = 32

        self.places = places
        self.radius_factor = radius_factor
        self.norm_type = norm_type

        self.ref_points = generate_ref_proxies(approx_nproxy)

    @property
    def ambient_dim(self) -> int:
        """Ambient dimension of the proxy geometry."""
        return self.places.ambient_dim

    @property
    def nproxy(self) -> int:
        """Number of proxy points in a single proxy ball."""
        return self.ref_points.shape[1]

    def get_centers_kernel_ex(self, actx: PyOpenCLArrayContext) -> lp.ExecutorBase:
        return make_compute_cluster_centers_kernel_ex(
                actx, self.ambient_dim, self.norm_type)

    @abstractmethod
    def get_radii_kernel_ex(self, actx: PyOpenCLArrayContext) -> lp.ExecutorBase:
        pass

    @log_process(logger)
    def __call__(self,
            actx: PyOpenCLArrayContext,
            source_dd: DOFDescriptorLike | None,
            dof_index: IndexList,
            **kwargs: ArrayContainer) -> ProxyClusterGeometryData:
        """Generate proxy points for each cluster in *dof_index_set* with nodes in
        the discretization *source_dd*.

        :arg source_dd: a :class:`~pytential.symbolic.dof_desc.DOFDescriptor`
            for the discretization on which the proxy points are to be
            generated.
        """
        if source_dd is None:
            source_dd = self.places.auto_source
        dd = sym.as_dofdesc(source_dd)

        discr = self.places.get_discretization(dd.geometry, dd.discr_stage)
        assert isinstance(discr, Discretization)

        # {{{ get proxy centers and radii

        sources = flatten(discr.nodes(), actx, leaf_class=DOFArray)

        knl = self.get_centers_kernel_ex(actx)
        _, (centers_dev,) = knl(actx.queue,
                sources=sources,
                srcindices=dof_index.indices,
                srcstarts=dof_index.starts)

        knl = self.get_radii_kernel_ex(actx)
        _, (cluster_radii,) = knl(actx.queue,
                sources=sources,
                srcindices=dof_index.indices,
                srcstarts=dof_index.starts,
                proxy_centers=centers_dev,
                **kwargs)

        radii_dev = self.radius_factor * cluster_radii

        # }}}

        # {{{ build proxy points for each cluster

        centers = np.vstack(actx.to_numpy(centers_dev))
        radii = actx.to_numpy(radii_dev)

        nproxy = self.nproxy * dof_index.nclusters
        proxies = np.empty((self.ambient_dim, nproxy), dtype=centers.dtype)
        pxy_nr_base = 0

        for i in range(dof_index.nclusters):
            points = radii[i] * self.ref_points + centers[:, i].reshape(-1, 1)
            proxies[:, pxy_nr_base:pxy_nr_base + self.nproxy] = points

            pxy_nr_base += self.nproxy

        # }}}

        pxyindices = np.arange(0, nproxy, dtype=dof_index.indices.dtype)
        pxystarts = np.arange(0, nproxy + 1, self.nproxy)

        from pytential.linalg import make_index_list
        return ProxyClusterGeometryData(
                places=self.places,
                dofdesc=dd,
                srcindex=dof_index,
                pxyindex=make_index_list(pxyindices, pxystarts),
                points=actx.freeze(actx.from_numpy(proxies)),
                centers=actx.freeze(centers_dev),
                radii=actx.freeze(radii_dev),
                cluster_radii=actx.freeze(cluster_radii),
                )


def make_compute_cluster_radii_kernel_ex(
        actx: PyOpenCLArrayContext, ndim: int) -> lp.ExecutorBase:
    @memoize_in(actx, (make_compute_cluster_radii_kernel_ex, ndim))
    def prg():
        knl = lp.make_kernel([
            "{[icluster]: 0 <= icluster < nclusters}",
            "{[i]: 0 <= i < npoints}",
            "{[idim]: 0 <= idim < ndim}"
            ],
            """
            for icluster
                <> ioffset = srcstarts[icluster]
                <> npoints = srcstarts[icluster + 1] - ioffset
                <> cluster_radius = reduce(max, i, sqrt(simul_reduce(sum, idim, \
                        (proxy_centers[idim, icluster]
                        - sources[idim, srcindices[i + ioffset]]) ** 2)
                        ))

                proxy_radius[icluster] = cluster_radius
            end
            """, [
                lp.GlobalArg("sources", None,
                    shape=(ndim, "nsources"), dim_tags="sep,C", offset=lp.auto),
                lp.ValueArg("nsources", np.int64),
                ...
                ],
            name="compute_cluster_radii_knl",
            assumptions="ndim>=1 and nclusters>=1",
            fixed_parameters={"ndim": ndim},
            lang_version=lp.MOST_RECENT_LANGUAGE_VERSION,
            )

        knl = lp.tag_inames(knl, "idim*:unr")
        knl = lp.split_iname(knl, "icluster", 64, outer_tag="g.0")

        return knl.executor(actx.context)

    return prg()


class ProxyGenerator(ProxyGeneratorBase):
    """A proxy point generator that only considers the points in the current
    cluster when determining the radius of the proxy ball.
    """

    @override
    def get_radii_kernel_ex(self, actx: PyOpenCLArrayContext) -> lp.ExecutorBase:
        return make_compute_cluster_radii_kernel_ex(actx, self.ambient_dim)


def make_compute_cluster_qbx_radii_kernel_ex(
        actx: PyOpenCLArrayContext, ndim: int) -> lp.ExecutorBase:
    @memoize_in(actx, (make_compute_cluster_qbx_radii_kernel_ex, ndim))
    def prg() -> lp.ExecutorBase:
        knl = lp.make_kernel([
            "{[icluster]: 0 <= icluster < nclusters}",
            "{[i]: 0 <= i < npoints}",
            "{[idim]: 0 <= idim < ndim}"
            ],
            """
            for icluster
                <> ioffset = srcstarts[icluster]
                <> npoints = srcstarts[icluster + 1] - ioffset

                <> rqbx_int = simul_reduce(max, i, sqrt(simul_reduce(sum, idim, \
                        (proxy_centers[idim, icluster] -
                         center_int[idim, srcindices[i + ioffset]]) ** 2)) + \
                         expansion_radii[srcindices[i + ioffset]])
                <> rqbx_ext = simul_reduce(max, i, sqrt(simul_reduce(sum, idim, \
                        (proxy_centers[idim, icluster] -
                         center_ext[idim, srcindices[i + ioffset]]) ** 2)) + \
                         expansion_radii[srcindices[i + ioffset]]) \
                         {dup=idim}

                <> rqbx = rqbx_int if rqbx_ext < rqbx_int else rqbx_ext

                proxy_radius[icluster] = rqbx
            end
            """, [
                lp.GlobalArg("sources", None,
                    shape=(ndim, "nsources"), dim_tags="sep,C", offset=lp.auto),
                lp.GlobalArg("center_int", None,
                    shape=(ndim, "nsources"), dim_tags="sep,C", offset=lp.auto),
                lp.GlobalArg("center_ext", None,
                    shape=(ndim, "nsources"), dim_tags="sep,C", offset=lp.auto),
                lp.ValueArg("nsources", np.int64),
                ...
                ],
            name="compute_cluster_qbx_radii_knl",
            assumptions="ndim>=1 and nclusters>=1",
            fixed_parameters={"ndim": ndim},
            lang_version=lp.MOST_RECENT_LANGUAGE_VERSION,
            )

        knl = lp.tag_inames(knl, "idim*:unr")
        knl = lp.split_iname(knl, "icluster", 64, outer_tag="g.0")

        return knl.executor(actx.context)

    return prg()


class QBXProxyGenerator(ProxyGeneratorBase):
    """A proxy point generator that also considers the QBX expansion
    when determining the radius of the proxy ball.
    """

    @override
    def get_radii_kernel_ex(self, actx: PyOpenCLArrayContext) -> lp.ExecutorBase:
        return make_compute_cluster_qbx_radii_kernel_ex(actx, self.ambient_dim)

    @override
    @log_process(logger)
    def __call__(self,
            actx: PyOpenCLArrayContext,
            source_dd: DOFDescriptorLike | None,
            dof_index: IndexList,
            **kwargs: ArrayContainer) -> ProxyClusterGeometryData:
        if source_dd is None:
            source_dd = self.places.auto_source
        dd = sym.as_dofdesc(source_dd)

        radii = cast("ArrayContainer", bind(
            self.places,
            sym.expansion_radii(self.ambient_dim, dofdesc=dd)
            )(actx))
        center_int = cast("ArrayContainer", bind(
            self.places,
            sym.expansion_centers(self.ambient_dim, -1, dofdesc=dd)
            )(actx))
        center_ext = cast("ArrayContainer", bind(
            self.places,
            sym.expansion_centers(self.ambient_dim, +1, dofdesc=dd)
            )(actx))

        return super().__call__(actx, dd, dof_index,
                expansion_radii=flatten(radii, actx),
                center_int=flatten(center_int, actx, leaf_class=DOFArray),
                center_ext=flatten(center_ext, actx, leaf_class=DOFArray),
                **kwargs)

# }}}


# {{{ gather_cluster_neighbor_points

@log_process(logger)
def gather_cluster_neighbor_points(
        actx: PyOpenCLArrayContext,
        pxy: ProxyClusterGeometryData,
        tgtindex: IndexList | None = None,
        *,
        max_particles_in_box: int | None = None) -> IndexList:
    r"""Generate a set of neighboring points for each cluster of points in *pxy*.

    Neighboring points of a cluster :math:`i` are defined as all the points
    from *tgtindex* that are inside the proxy ball :math:`i` but outside the
    cluster itself. For example, given a cluster with radius :math:`r_s` and
    proxy radius :math:`r_p > r_s`, then we gather all points such that
    :math:`r_s < \|\mathbf{x}\| <= r_p`.
    """

    srcindex = pxy.srcindex
    if tgtindex is None:
        tgtindex = srcindex

    nclusters = srcindex.nclusters
    if tgtindex.nclusters != nclusters:
        raise ValueError("'tgtindex' has a different number of clusters: "
                         f"'{tgtindex.nclusters}' (expected {nclusters})")

    if max_particles_in_box is None:
        max_particles_in_box = _DEFAULT_MAX_PARTICLES_IN_BOX

    dofdesc = pxy.dofdesc
    lpot_source = pxy.places.get_geometry(dofdesc.geometry)
    discr = pxy.places.get_discretization(dofdesc.geometry, dofdesc.discr_stage)

    assert (
        dofdesc.discr_stage is None
        or isinstance(lpot_source, QBXLayerPotentialSource)
        ), (dofdesc, type(lpot_source))
    assert isinstance(discr, Discretization)

    # {{{ get only sources in the current cluster set

    @memoize_in(actx,
            (gather_cluster_neighbor_points, discr.ambient_dim, "picker_knl"))
    def prg() -> lp.ExecutorBase:
        knl = lp.make_kernel(
            "{[idim, i]: 0 <= idim < ndim and 0 <= i < npoints}",
            """
            result[idim, i] = ary[idim, srcindices[i]]
            """, [
                lp.GlobalArg("ary", None,
                    shape=(discr.ambient_dim, "ndofs"), dim_tags="sep,C"),
                lp.ValueArg("ndofs", np.dtype(np.int64)),
                ...],
            name="picker_knl",
            assumptions="ndim>=1 and npoints>=1",
            fixed_parameters={"ndim": discr.ambient_dim},
            lang_version=lp.MOST_RECENT_LANGUAGE_VERSION,
            )

        knl = lp.tag_inames(knl, "idim*:unr")
        knl = lp.split_iname(knl, "i", 64, outer_tag="g.0")

        return knl.executor(actx.context)

    _, (targets,) = prg()(actx.queue,
            ary=flatten(discr.nodes(), actx, leaf_class=DOFArray),
            srcindices=tgtindex.indices)

    # }}}

    # {{{ perform area query

    from pytential.qbx.utils import tree_code_container

    # NOTE: use the base source's actx for caching the code -- that has
    # the best chance of surviving even when updating the lpot_source
    setup_actx = discr._setup_actx
    assert isinstance(setup_actx, PyOpenCLArrayContext)

    tcc = tree_code_container(setup_actx)
    tree, _ = tcc.build_tree()(actx, targets, max_particles_in_box=max_particles_in_box)
    query, _ = tcc.build_area_query()(actx, tree, pxy.centers, pxy.radii)

    tree = actx.to_numpy(tree)
    query = actx.to_numpy(query)

    # }}}

    # {{{ retrieve results

    pxycenters = actx.to_numpy(pxy.centers)
    pxyradii = actx.to_numpy(pxy.radii)

    eps = float(100 * np.finfo(pxyradii.dtype).eps)
    nbrindices = np.empty(nclusters, dtype=object)
    for icluster in range(nclusters):
        # get list of boxes intersecting the current ball
        istart = query.leaves_near_ball_starts[icluster]
        iend = query.leaves_near_ball_starts[icluster + 1]
        iboxes = query.leaves_near_ball_lists[istart:iend]

        if (iend - istart) <= 0:
            nbrindices[icluster] = np.empty(0, dtype=np.int64)
            continue

        # get nodes inside the boxes
        istart = tree.box_source_starts[iboxes]
        iend = istart + tree.box_source_counts_cumul[iboxes]
        isources = np.hstack([
            np.arange(s, e) for s, e in zip(istart, iend, strict=True)])
        nodes = np.vstack([s[isources] for s in tree.sources])
        isources = tree.user_source_ids[isources]

        # get nodes inside the ball but outside the current cluster
        center = pxycenters[:, icluster].reshape(-1, 1)
        radii = la.norm(nodes - center, axis=0) - eps
        mask = (
            (radii <= pxyradii[icluster])
            & ((isources < tgtindex.starts[icluster])
               | (tgtindex.starts[icluster + 1] <= isources)))

        nbrindices[icluster] = tgtindex.indices[isources[mask]]
        if nbrindices[icluster].size == 0:
            logger.warning("Cluster '%d' has no neighbors. You might need to "
                           "increase the proxy 'radius_factor'.", icluster)

    # }}}

    from pytential.linalg import make_index_list
    return make_index_list(indices=nbrindices)

# }}}

# vim: foldmethod=marker
